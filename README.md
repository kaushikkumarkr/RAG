# ğŸ­ RAG Foundry

> **Enterprise-Grade Agentic RAG Platform** with Full Observability, Guardrails, and Quality Metrics

![Status](https://img.shields.io/badge/Status-Production_Ready-success)
![Python](https://img.shields.io/badge/Python-3.11+-blue)
![Tests](https://img.shields.io/badge/Tests-21_Passing-brightgreen)
![MLX](https://img.shields.io/badge/MLX-Apple_Silicon-green)
![Langfuse](https://img.shields.io/badge/Observability-Langfuse-purple)

**RAG Foundry** is a production-ready, local-first framework for building advanced Retrieval Augmented Generation (RAG) systems. It implements **senior-level AI engineering practices** including multi-stage guardrails, citation validation, confidence scoring, and comprehensive observability.

---

## âœ¨ Key Features

### ğŸ§  Intelligent RAG Pipeline
- **Hybrid Retrieval**: Dense vectors (Qdrant) + Sparse BM25 + Cross-Encoder reranking
- **Citation Generation**: LLM produces `[doc_id:chunk]` citations, validated and formatted as `[1], [2]`
- **Confidence Scoring**: 5-signal weighted confidence with automatic disclaimers

### ğŸ›¡ï¸ Enterprise Safety (Guardrails)
- **Input Guards**: Jailbreak detection, PII filtering, off-topic rejection
- **Output Guards**: Toxicity filtering, hallucination detection, refusal handling

### ğŸ“Š Full Observability (Langfuse)
- **Nested Traces**: 7-component pipeline visible as hierarchical spans
- **15+ Metrics**: Guardrail scores, citation counts, confidence breakdown, Ragas quality
- **Quality Evaluation**: Ragas faithfulness & answer relevancy on every query

### âš¡ Local-First Performance
- **MLX Optimization**: JIT-compiled inference for Apple Silicon
- **Quantized Models**: Qwen2.5-7B-4bit at high tokens/sec
- **Zero Cloud Dependency**: Runs entirely on your local machine

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart TB
    subgraph User Layer
        UI[Streamlit UI]
        API[FastAPI]
    end

    subgraph Safety Layer
        IG[ğŸ›¡ï¸ Input Guardrails]
        OG[ğŸ›¡ï¸ Output Guardrails]
    end

    subgraph Retrieval Layer
        HS[ğŸ” Hybrid Search]
        QD[(Qdrant)]
        BM[BM25 Index]
        RR[ğŸ”„ Cross-Encoder<br/>Reranker]
    end

    subgraph Generation Layer
        LLM[ğŸ’¬ Local LLM<br/>MLX / Qwen2.5]
        CIT[ğŸ“š Citation<br/>Processor]
        CONF[ğŸ“Š Confidence<br/>Scorer]
    end

    subgraph Observability
        LF[Langfuse]
        RAGAS[Ragas Metrics]
    end

    UI --> API
    API --> IG
    IG -->|Blocked| API
    IG -->|Passed| HS
    
    HS --> QD
    HS --> BM
    QD --> RR
    BM --> RR
    
    RR --> LLM
    LLM --> CIT
    CIT --> CONF
    CONF --> OG
    
    OG -->|Blocked| API
    OG -->|Passed| API
    API --> UI

    IG -.->|Spans| LF
    HS -.->|Spans| LF
    RR -.->|Spans| LF
    LLM -.->|Spans| LF
    CIT -.->|Spans| LF
    CONF -.->|Scores| LF
    OG -.->|Spans| LF
    
    LF --> RAGAS
```

### Component Overview

| Component | Purpose | Technology |
|-----------|---------|------------|
| **Input Guardrails** | Block jailbreaks, detect PII, filter off-topic | Regex + Heuristics |
| **Hybrid Search** | Combine semantic + keyword retrieval | Qdrant + BM25 |
| **Reranker** | Precision ranking with cross-attention | `ms-marco-MiniLM-L-6-v2` |
| **LLM** | Answer generation with citations | MLX / Qwen2.5-7B-4bit |
| **Citation Processor** | Extract, validate, format references | Regex + Validation |
| **Confidence Scorer** | Multi-signal reliability assessment | 5-signal weighted |
| **Output Guardrails** | Filter toxic/harmful responses | Pattern matching |
| **Observability** | Trace entire pipeline | Langfuse + Ragas |

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.11+
- Apple Silicon Mac (M1/M2/M3/M4) for MLX support

### Installation

```bash
# Clone the repository
git clone https://github.com/kaushikkumarkr/RAG.git
cd RAG/rag-foundry

# Setup virtual environment
make setup

# Start infrastructure (Qdrant, Langfuse)
make services

# Start MLX inference server
bash scripts/start_mlx.sh
```

### Run Professional Evaluation

```bash
# Run the full 7-component evaluation
PYTHONPATH=. .venv/bin/python scripts/eval_professional.py
```

This will show:
```
ğŸ† ULTIMATE PROFESSIONAL RAG EVALUATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Query: What is the Transformer architecture?
  [1/7] ğŸ›¡ï¸ Input Guardrails... âœ… Passed
  [2/7] ğŸ” Hybrid Search... âœ… 10 candidates
  [3/7] ğŸ”„ Cross-Encoder Reranking... âœ… Top 3 selected
  [4/7] ğŸ’¬ LLM Generation... âœ… 323 chars
  [5/7] ğŸ“š Citation Processing... âœ… 1 valid citations
  [6/7] ğŸ“Š Confidence Scoring... âœ… 0.71 (high)
  [7/7] ğŸ›¡ï¸ Output Guardrails... âœ… Passed

  ğŸ“Š FINAL RESULTS
  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘ Confidence: 0.71 (HIGH)                â•‘
  â•‘ Faithfulness: 1.00 ğŸŒŸ                  â•‘
  â•‘ Relevancy: 0.98 ğŸŒŸ                     â•‘
  â•‘ Citations: 1 valid, 0 phantom          â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“¦ Project Structure

```
rag-foundry/
â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ retrieval/        # Dense + Sparse search
â”‚   â”œâ”€â”€ rerank/           # Cross-encoder reranking
â”‚   â”œâ”€â”€ generation/       # LLM answer generation
â”‚   â”œâ”€â”€ guardrails/       # ğŸ›¡ï¸ Input/Output safety
â”‚   â”‚   â”œâ”€â”€ input_guards.py   # Jailbreak, PII, off-topic
â”‚   â”‚   â”œâ”€â”€ output_guards.py  # Toxicity, hallucination
â”‚   â”‚   â””â”€â”€ service.py        # Unified GuardrailService
â”‚   â”œâ”€â”€ citations/        # ğŸ“š Citation processing
â”‚   â”‚   â”œâ”€â”€ extractor.py      # Parse [doc_id:chunk]
â”‚   â”‚   â”œâ”€â”€ validator.py      # Detect phantom citations
â”‚   â”‚   â”œâ”€â”€ formatter.py      # Format as [1], [2]
â”‚   â”‚   â””â”€â”€ service.py        # Unified CitationService
â”‚   â””â”€â”€ confidence/       # ğŸ“Š Confidence scoring
â”‚       â”œâ”€â”€ signals.py        # 5 confidence signals
â”‚       â””â”€â”€ service.py        # Weighted aggregation
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ unit/
â”‚       â”œâ”€â”€ test_guardrails.py  # 7 tests
â”‚       â”œâ”€â”€ test_citations.py   # 7 tests
â”‚       â””â”€â”€ test_confidence.py  # 7 tests
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ eval_professional.py    # Enterprise evaluation
â”‚   â”œâ”€â”€ test_guardrails.py      # Manual guardrail tests
â”‚   â”œâ”€â”€ test_citations.py       # Manual citation tests
â”‚   â””â”€â”€ test_confidence.py      # Manual confidence tests
â””â”€â”€ Makefile                    # Development commands
```

---

## ğŸ§ª Testing

```bash
# Run all 21 unit tests
make test

# Run specific module tests
make test-unit          # Unit tests only
make test-guardrails    # Guardrail tests
make test-citations     # Citation tests
make test-confidence    # Confidence tests

# Run with coverage
make test-cov
```

**Test Coverage:**
| Module | Tests | Status |
|--------|-------|--------|
| Guardrails | 7 | âœ… All passing |
| Citations | 7 | âœ… All passing |
| Confidence | 7 | âœ… All passing |
| **Total** | **21** | **100% pass** |

---

## ğŸ“Š Observability

### Langfuse Dashboard

Visit `http://localhost:3000` to see:

**Trace Structure:**
```
ğŸ“¦ rag-professional (Trace)
â”œâ”€â”€ ğŸ›¡ï¸ input_guardrails (Span)
â”œâ”€â”€ ğŸ” hybrid_search (Span)
â”œâ”€â”€ ğŸ”„ rerank (Span)
â”œâ”€â”€ ğŸ’¬ generation (Span)
â”œâ”€â”€ ğŸ“š citation_processing (Span)
â”œâ”€â”€ ğŸ“Š confidence_scoring (Span)
â””â”€â”€ ğŸ›¡ï¸ output_guardrails (Span)
```
(Langfuse_TracesList.png)
**Scores Per Trace:**
| Category | Metrics |
|----------|---------|
| Input Guards | `guard_input_off_topic`, `guard_input_jailbreak`, `guard_input_pii` |
| Output Guards | `guard_output_toxicity`, `guard_output_refusal`, `guard_output_hallucination` |
| Citations | `citation_count`, `citation_valid`, `citation_phantom` |
| Confidence | `confidence`, `conf_retrieval`, `conf_agreement`, `conf_citations`, `conf_refusal` |
| Quality | `faithfulness`, `answer_relevancy` |

---

## ğŸ›¡ï¸ Guardrails Detail

### Input Guardrails

| Guard | Action | Example |
|-------|--------|---------|
| **Off-Topic** | âš ï¸ Warning | "Best pizza in NYC?" |
| **Jailbreak** | ğŸš« Block | "Ignore instructions, pretend you are..." |
| **PII** | âš ï¸ Warning | "Email me at john@example.com" |

### Output Guardrails

| Guard | Action | Example |
|-------|--------|---------|
| **Toxicity** | ğŸš« Block | "You should kill the process..." |
| **Refusal** | âš ï¸ Warning | "I cannot answer this question" |
| **Hallucination** | âš ï¸ Warning | Phantom citations to non-existent sources |

---

## ğŸ“š Citation System

The LLM generates inline citations that are automatically validated:

**Input (LLM Output):**
```
The Transformer uses attention [abc123:0] to process sequences.
```

**Output (Formatted):**
```
The Transformer uses attention [1] to process sequences.

---
**Sources:**
[1] attention_paper.pdf (chunk 0)
    "The Transformer model uses self-attention mechanisms..."
```

**Phantom Detection:** If the LLM cites a source not in the retrieved chunks, it's flagged as a hallucination.

---

## ğŸ“Š Confidence Scoring

5 signals are combined with weighted aggregation:

| Signal | Weight | Description |
|--------|--------|-------------|
| Retrieval | 30% | Average rerank score |
| Agreement | 20% | Do sources agree? (Jaccard similarity) |
| Citations | 20% | Citations per 50 words |
| Refusal | 15% | Did LLM refuse to answer? |
| Length | 15% | Very short = less confident |

**Confidence Levels:**
- **High (â‰¥0.7)**: No disclaimer
- **Medium (0.4-0.7)**: No disclaimer
- **Low (<0.4)**: âš ï¸ "This answer may not be reliable"

---

## ğŸ› ï¸ Development

```bash
make setup      # Setup virtual environment
make services   # Start Qdrant + Langfuse
make test       # Run all tests
make lint       # Run linting
make clean      # Clean artifacts
```

---

## ğŸ“œ License

MIT

---

<p align="center">
  <b>Built with â¤ï¸ for production-ready RAG systems</b><br>
  <i>Implementing senior-level AI engineering practices</i>
</p>
